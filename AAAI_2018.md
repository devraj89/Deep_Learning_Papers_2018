
[1] Zero-Shot Learning with Attribute Selection
--------------------------------------------------------

https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/download/16350/16272

-- a very interesting paper showing the importance of attributes in ZSL

-- but only deals with seen train categories ... how to incorporate the unseen also on the fly ?

-- deep model incorporation ? how ? 

-- similar related paper from years back in ECCV 2012

Augmented Attribute Representations

http://mlg.eng.cam.ac.uk/pub/pdf/ShaQuaLam12.pdf

[2] Binary Generative Adversarial Networks for Image Retrieval
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17150/15712

-- an interesting paper basically their attribute to generate the  figures are discrete in nature

-- also looks like you can basically have a control over what amount of similarity you wish to give 

-- perhaps can be used to generate attributes for the zsl on the fly and help in better attribute generation ?

[3] Partial Multi-View Outlier Detection Based on Collective Learning
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17166/15700

-- an interesting problem

-- basically detection of attributes across modalities (but also with the possibility of missing data)

[4] Unsupervised Generative Adversarial Cross-Modal Hashing
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16746/15730


[5] A Deep Model with Local Surrogate Loss for General Cost-Sensitive Multi-label Learning
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17307/16685

-- loss functions specificallt for the multi-label learning 

-- they have provided comparisons with the weighted bce loss but not with mse loss 

-- may be related to my semi-supervised submission work

[6] On Trivial Solution and High Correlation Problems in Deep Supervised Hashing
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16351/15936

-- same conclusion as my GrowBit paper that bits can be decoupled but they are saying that it is bad and bits are being correlated in that case so they suggest some models like dividing the input data into groups, using slightly different models, etc

-- incremental learning is just mentioned in passing (though no new tags/annotations as done in GrowBit is considered)

-- single modal hashing


[7] Learning from Semi-Supervised Weak-Label Dataâˆ—
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17022/16605

-- a new problem statement where basically the data is multi-label 

-- + 1 tag is present / -1 means tag is absent 

-- data is given as +1 and 0 which means that 0 can either mean +1/-1

-- paper proposes a non-deep solution


[8] Asking Friendly Strangers: Non-Semantic Attribute Transfer
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16287/16321

-- Attributes can be used to recognize unseen objects from a textual description. Their learning is oftentimes accomplished with a large amount of annotations, e.g. around 160k-180k, but what happens if for a given attribute, we do not have many annotations? The standard approach would be to perform transfer learning, where we use source models trained on other attributes, to learn a separate target attribute. However existing approaches only consider transfer from attributes in the same domain i.e. they perform semantic transfer between attributes that have related meaning. Instead, we propose to perform non-semantic transfer from attributes that may be in different domains, hence they have no semantic relation to the target attributes. We develop an attention-guided transfer architecture that learns how to weigh the available source attribute classifiers, and applies them to image features for the attribute name of interest, to make predictions for that attribute. We validate our approach on 272 attributes from five domains: animals, objects, scenes, shoes and textures. We show that semantically unrelated attributes provide knowledge that helps improve the accuracy of the target attribute of interest, more so than only allowing transfer from semantically related attributes.

-- attribute transfer for domain adaptation

[9] Deep Learning for Case-Based Reasoning through Prototypes: A Neural Network that Explains Its Predictions
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17082/16552

code : https://github.com/OscarcarLi/PrototypeDL

-- interesting paper regarding the interpretability of predictions

-- very very interesting paper which might be useful in (1) learning a better softmax by using the prototypes as centers of data (2) for novelty detection because of the interpretability factor (3) using entropy of the protype layer itself might even work

[12] Supervised Deep Hashing for Hierarchical Labeled Data
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16330/16336

-- an interesting take on the hierarchical labeled data

-- single modal application, with similar formulation to my work in CVPR, TIP (even uses SGD to solve it)

-- can extending it to cross-modal be a work? also in each label the similarity is either "1" or "0" ... labels are denoted using a single tag/annotation? can a label also have multiple tags? or rather my question is this does it mean like for a dataset having 81-tags to have 81 hierarchical labels? also what if all of them do not have the same root labels ? like different root labels and inside it hierarchies exists ?


[13] Towards Affordable Semantic Searching:Zero-Shot Retrieval via Dominant Attributes
--------------------------------------------------------

https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16626

-- an interesting paper 

-- Instance-level retrieval has become an essential paradigm toindex and retrieves images from large-scale databases. Con-ventional instance search requires at least an example ofthe query image to retrieve images that contain the sameobject instance. Existing semantic retrieval can only searchsemantically-relatedimages, such as those sharing the samecategory or a set of tags, not the exact instances. Meanwhile,the unrealistic assumption is that all categories or tags areknown beforehand. Training models for these semantic con-cepts highly rely on instance-level attributes or human cap-tions which are expensive to acquire. Given the above chal-lenges, this paper studies theZero-shot Retrievalproblem thataims for instance-level image search using only a few domi-nant attributes. The contributions are: 1) we utilise automaticword embedding to infer class-level attributes to circumventexpensive human labelling; 2) the inferred class-attributes canbe extended into discriminative instance attributes throughour proposed Latent Instance Attributes Discovery (LIAD)algorithm; 3) our method is not restricted to complete at-tribute signatures, query of dominant attributes can also bedealt with. On two benchmarks, CUB and SUN, extensive ex-periments demonstrate that our method can achieve promis-ing performance for the problem. Moreover, our approach canalso benefit conventional ZSL tasks.

[14] 













