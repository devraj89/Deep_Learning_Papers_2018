
[1] Zero-Shot Learning with Attribute Selection
--------------------------------------------------------

https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/download/16350/16272

-- a very interesting paper showing the importance of attributes in ZSL

-- but only deals with seen train categories ... how to incorporate the unseen also on the fly ?

-- deep model incorporation ? how ? 

-- similar related paper from years back in ECCV 2012

Augmented Attribute Representations

http://mlg.eng.cam.ac.uk/pub/pdf/ShaQuaLam12.pdf

[2] Binary Generative Adversarial Networks for Image Retrieval
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17150/15712

-- an interesting paper basically their attribute to generate the figures are discrete in nature

-- basically an image is send through a network to produce some hash codes which itself forms the conditional input to a generator along with the sampled noise and then the generated output is measured w.r.t to the orginal sent image. question is why really an adversarial loss is required (what is the use of z ?)

-- perhaps can be useful for supritam's work regarding novelty detection based on the reconstruction part

[3] Partial Multi-View Outlier Detection Based on Collective Learning
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17166/15700

-- an interesting problem

-- basically detection of attributes across modalities (but also with the possibility of missing data)

[4] Unsupervised Generative Adversarial Cross-Modal Hashing
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16746/15730


[5] A Deep Model with Local Surrogate Loss for General Cost-Sensitive Multi-label Learning
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17307/16685

-- loss functions specificallt for the multi-label learning 

-- they have provided comparisons with the weighted bce loss but not with mse loss 

-- may be related to my semi-supervised submission work

[6] On Trivial Solution and High Correlation Problems in Deep Supervised Hashing
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16351/15936

-- same conclusion as my GrowBit paper that bits can be decoupled but they are saying that it is bad and bits are being correlated in that case so they suggest some models like dividing the input data into groups, using slightly different models, etc

-- incremental learning is just mentioned in passing (though no new tags/annotations as done in GrowBit is considered)

-- single modal hashing


[7] Learning from Semi-Supervised Weak-Label Dataâˆ—
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17022/16605

-- a new problem statement where basically the data is multi-label 

-- + 1 tag is present / -1 means tag is absent 

-- data is given as +1 and 0 which means that 0 can either mean +1/-1

-- paper proposes a non-deep solution


[8] Asking Friendly Strangers: Non-Semantic Attribute Transfer
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16287/16321

-- Attributes can be used to recognize unseen objects from a textual description. Their learning is oftentimes accomplished with a large amount of annotations, e.g. around 160k-180k, but what happens if for a given attribute, we do not have many annotations? The standard approach would be to perform transfer learning, where we use source models trained on other attributes, to learn a separate target attribute. However existing approaches only consider transfer from attributes in the same domain i.e. they perform semantic transfer between attributes that have related meaning. Instead, we propose to perform non-semantic transfer from attributes that may be in different domains, hence they have no semantic relation to the target attributes. We develop an attention-guided transfer architecture that learns how to weigh the available source attribute classifiers, and applies them to image features for the attribute name of interest, to make predictions for that attribute. We validate our approach on 272 attributes from five domains: animals, objects, scenes, shoes and textures. We show that semantically unrelated attributes provide knowledge that helps improve the accuracy of the target attribute of interest, more so than only allowing transfer from semantically related attributes.

-- attribute transfer for domain adaptation

[9] Deep Learning for Case-Based Reasoning through Prototypes: A Neural Network that Explains Its Predictions
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17082/16552

code : https://github.com/OscarcarLi/PrototypeDL

-- interesting paper regarding the interpretability of predictions

-- very very interesting paper which might be useful in (1) learning a better softmax by using the prototypes as centers of data (2) for novelty detection because of the interpretability factor (3) using entropy of the protype layer itself might even work

[12] Supervised Deep Hashing for Hierarchical Labeled Data
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16330/16336

-- an interesting take on the hierarchical labeled data

-- single modal application, with similar formulation to my work in CVPR, TIP (even uses SGD to solve it)

-- can extending it to cross-modal be a work? also in each label the similarity is either "1" or "0" ... labels are denoted using a single tag/annotation? can a label also have multiple tags? or rather my question is this does it mean like for a dataset having 81-tags to have 81 hierarchical labels? also what if all of them do not have the same root labels ? like different root labels and inside it hierarchies exists ?


[13] Towards Affordable Semantic Searching:Zero-Shot Retrieval via Dominant Attributes
--------------------------------------------------------

https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16626

-- an interesting paper 

-- Instance-level retrieval has become an essential paradigm toindex and retrieves images from large-scale databases. Con-ventional instance search requires at least an example ofthe query image to retrieve images that contain the sameobject instance. Existing semantic retrieval can only searchsemantically-relatedimages, such as those sharing the samecategory or a set of tags, not the exact instances. Meanwhile,the unrealistic assumption is that all categories or tags areknown beforehand. Training models for these semantic con-cepts highly rely on instance-level attributes or human cap-tions which are expensive to acquire. Given the above chal-lenges, this paper studies theZero-shot Retrievalproblem thataims for instance-level image search using only a few domi-nant attributes. The contributions are: 1) we utilise automaticword embedding to infer class-level attributes to circumventexpensive human labelling; 2) the inferred class-attributes canbe extended into discriminative instance attributes throughour proposed Latent Instance Attributes Discovery (LIAD)algorithm; 3) our method is not restricted to complete at-tribute signatures, query of dominant attributes can also bedealt with. On two benchmarks, CUB and SUN, extensive ex-periments demonstrate that our method can achieve promis-ing performance for the problem. Moreover, our approach canalso benefit conventional ZSL tasks.

[14] Kill Two Birds with One Stone: Weakly-Supervised Neural Network for Image Annotation and Tag Refinement
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16445/16356

-- The number of social images has exploded by the wide adoption of social networks, and people like to share their comments about them. These comments can be a description of the image, or some objects, attributes, scenes in it, which are normally used as the user-provided tags. However, it is well-known that user-provided tags are incomplete and imprecise to some extent. Directly using them can damage the performance of related applications, such as the image annotation and retrieval. In this paper, we propose to learn an image annotation model and refine the user-provided tags simultaneously in a weakly-supervised manner. The deep neural network is utilized as the image feature learning and backbone annotation model, while visual consistency, semantic dependency, and user-error sparsity are introduced as the constraints at the batch level to alleviate the tag noise. Therefore, our model is highly flexible and stable to handle large-scale image sets. Experimental results on two benchmark datasets indicate that our proposed model achieves the best performance compared to the state-of-the-art methods.

-- an interesting paper with three losses

-- loss 1 says that visual consistent images should have similar tags/annotations (makes sense)

-- loss 2 uses the Google distance and word2vec to address consistency in the tag domain ... like which tags should co-occur together ?

-- loss 3 makes use of the fact that the number of tags should be small so sparsity constraint is used













