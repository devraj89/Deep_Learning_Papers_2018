
[1] Zero-Shot Learning with Attribute Selection
--------------------------------------------------------

https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/download/16350/16272

-- a very interesting paper showing the importance of attributes in ZSL

-- but only deals with seen train categories ... how to incorporate the unseen also on the fly ?

-- deep model incorporation ? how ? 

-- similar related paper from years back in ECCV 2012

Augmented Attribute Representations

http://mlg.eng.cam.ac.uk/pub/pdf/ShaQuaLam12.pdf

[2] Binary Generative Adversarial Networks for Image Retrieval
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17150/15712

-- an interesting paper basically their attribute to generate the  figures are discrete in nature

-- also looks like you can basically have a control over what amount of similarity you wish to give 

-- perhaps can be used to generate attributes for the zsl on the fly and help in better attribute generation ?

[3] Partial Multi-View Outlier Detection Based on Collective Learning
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17166/15700

-- an interesting problem

-- basically detection of attributes across modalities (but also with the possibility of missing data)

[4] Unsupervised Generative Adversarial Cross-Modal Hashing
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16746/15730


[5] A Deep Model with Local Surrogate Loss for General Cost-Sensitive Multi-label Learning
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17307/16685

-- loss functions specificallt for the multi-label learning 

-- they have provided comparisons with the weighted bce loss but not with mse loss 

-- may be related to my semi-supervised submission work

[6] On Trivial Solution and High Correlation Problems in Deep Supervised Hashing
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16351/15936

-- same conclusion as my GrowBit paper that bits can be decoupled but they are saying that it is bad and bits are being correlated in that case so they suggest some models like dividing the input data into groups, using slightly different models, etc

-- incremental learning is just mentioned in passing (though no new tags/annotations as done in GrowBit is considered)

-- single modal hashing


[7] Learning from Semi-Supervised Weak-Label Dataâˆ—
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17022/16605

-- a new problem statement where basically the data is multi-label 

-- + 1 tag is present / -1 means tag is absent 

-- data is given as +1 and 0 which means that 0 can either mean +1/-1

-- paper proposes a non-deep solution


[8] Asking Friendly Strangers: Non-Semantic Attribute Transfer
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16287/16321

-- Attributes can be used to recognize unseen objects from a textual description. Their learning is oftentimes accomplished with a large amount of annotations, e.g. around 160k-180k, but what happens if for a given attribute, we do not have many annotations? The standard approach would be to perform transfer learning, where we use source models trained on other attributes, to learn a separate target attribute. However existing approaches only consider transfer from attributes in the same domain i.e. they perform semantic transfer between attributes that have related meaning. Instead, we propose to perform non-semantic transfer from attributes that may be in different domains, hence they have no semantic relation to the target attributes. We develop an attention-guided transfer architecture that learns how to weigh the available source attribute classifiers, and applies them to image features for the attribute name of interest, to make predictions for that attribute. We validate our approach on 272 attributes from five domains: animals, objects, scenes, shoes and textures. We show that semantically unrelated attributes provide knowledge that helps improve the accuracy of the target attribute of interest, more so than only allowing transfer from semantically related attributes.

-- attribute transfer for domain adaptation

[9] Deep Learning for Case-Based Reasoning through Prototypes: A Neural Network that Explains Its Predictions
--------------------------------------------------------

https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17082/16552

code : https://github.com/OscarcarLi/PrototypeDL

-- interesting paper regarding the interpretability of predictions




