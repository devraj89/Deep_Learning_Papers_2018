
[1] Equal But Not The Same: Understanding the Implicit Relationship Between Persuasive Images and Text 
------------------------------------------------

-- suggested by Siavaram

-- basically they are saying that the two domains do not give redundant information but rather complementary information and hence it is important to consider both of them

-- not like image captioning where basically they just say/read aloud what is given in the image 

[2] VSE++: Improving Visual-Semantic Embeddings with Hard Negatives
---------------------------------------------------------------------

-- We present a new technique for learning visual-semantic embeddings for cross-modal retrieval. Inspired by hard negative mining, the use of hard negatives in structured prediction, and ranking loss functions, we introduce a simple change to common loss functions used for multi-modal embeddings. That, combined with fine-tuning and use of augmented data, yields significant gains in retrieval performance. We showcase our approach, VSE++, on MS-COCO and Flickr30K datasets, using ablation studies and comparisons with existing methods. On MS-COCO our approach outperforms state-ofthe-art methods by 8.8% in caption retrieval and 11.3% in image retrieval (at R@1). 

-- another version of negative mining (introduces novelty into the triplet loss)

[3] Semantic Embedding for Sketch-Based 3D Shape Retrieval 
-----------------------------------------------------------

-- a simple paper for cross modal retrieval 

-- triplet loss but only sketch and 3d shape 

[4] Metric Learning for Novelty and Anomaly Detection
-----------------------------------------------------------

-- When neural networks process images which do not resemble the distribution seen during training, so called out-of-distribution images, they often make wrong predictions, and do so too confidently. The capability to detect out-of-distribution images is therefore crucial for many real-world applications. We divide out-of-distribution detection between novelty detection —images of classes which are not in the training set but are related to those—, and anomaly detection —images with classes which are unrelated to the training set. By related we mean they contain the same type of objects, like digits in MNIST and SVHN. Most existing work has focused on anomaly detection, and has addressed this problem considering networks trained with the cross-entropy loss. Differently from them, we propose to use metric learning which does not have the drawbackof the softmax layer (inherent to cross-entropy methods), which forces the network to divide its prediction power over the learned classes. We perform extensive experiments and evaluate both novelty and anomaly detection, even in a relevant application such as traffic sign recognition, obtaining comparable or better results than previous works. 

