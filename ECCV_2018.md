
[1] Deep Co-Training for Semi-Supervised Image Recognition
-----------------------------------------------------------

http://openaccess.thecvf.com/content_ECCV_2018/papers/Siyuan_Qiao_Deep_Co-Training_for_ECCV_2018_paper.pdf

-- interesting approach called co-training where multiple views of the same data 
are used to learn a semi-supervised model 

-- basically since the data is essentially the same, there is a chance that both the networks will collapse to the
same thing hence they are creating adversarial examples so that the networks provide complementary information
to one-another 

-- basically look at eqn (2) and (5) they are creating a new dataset D' with adversarial examples where the predictions of 
net1 is not equal to that of net2 . it is kind of that adversarial examples of net2 should not hamper the performance of net1.

-- basically WHAT NET 1 MAKES MISTAKES ON should not be CARRIED OVER TO THE MISTAKES OF NET 2

-- creating adversarial examples from one modality to another is a challenge 

[2] HybridNet: Classification and Reconstruction Cooperation for Semi-Supervised Learning
-------------------------------------------------------------------------------------------

https://github.com/dakshitagrawal97/HybridNet

https://arxiv.org/pdf/1807.11407.pdf

-- an interesting paper in which data is sent through two encoders Ec Eu and two decoders Dc and Du. The Ec and Dc are used for the discriminative pathway whereas the non-discriminative pathway is through Eu and Du.

-- and the outputs of the both Dc and Du should be able to reconstruct x otherwise the two decoders does partial reconstructions

-- check the intermediate reconstruction losses : this helps to make use of the Ec Dc for the reconstruction also and NOT ONLY Eu Du

-- check branch co-operation: loss : BASICALLY WHICHEVER BRANCH IS CONTRIBUTING LESS TO THE RECONSTRUCTION should be penalized
check eqn (6)

-- might be useful to check out the code 
